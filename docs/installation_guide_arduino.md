# How to transform your Arduino into an Speech Emotion Recognition Device with Edge Impulse

Welcome to this tutorial of how to create your own Speech Emotion Recognition (SER) device, at the end of this tutorial you will know how to implement your own tiny machine learning model for speech emotion recognition and implement it in real life on your Arduino Nano 33 BLE sense rev2 with **Edge Impulse**. 

This tutorial is part of the **MADI PROJECT** submitted to the Edge Impulse competition of Hackearth. 

1. Required Materials
2. Database
3. Edge Impulse Steps
4. Conclusion

## Required Materials
- [Edge Impulse Account](https://edgeimpulse.com/)
- Arduino Nano 33 BLE Sense rev2
- USB A to Micro USB Cable
- (optional)  OV7675 Camera

## Database
The database utilized for training the speech emotion recognition model, is [CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D) one of the most used database in the field of SER. For the porpouse of this proyect we selected the emotions of: Angry and Neutral. 

## Edge Impulse Steps

<img width="3244" height="3244" alt="1" src="https://github.com/user-attachments/assets/4445c89b-2264-4ff9-b76b-e756a03db632" />
<img width="3522" height="4106" alt="2" src="https://github.com/user-attachments/assets/43349804-fcc1-4c34-a0e9-8db8a1ef00d5" />
<img width="3098" height="3364" alt="3" src="https://github.com/user-attachments/assets/e748e035-35cc-4563-b2be-878f276e952f" />


